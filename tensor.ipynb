{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basic \n",
    "\n",
    "<hr>\n",
    "\n",
    "## 1. What is PyTorch\n",
    "\n",
    "PyTorch is an open source framework for machine learning (ML) and Deap Learning (DL) implementation.\n",
    "\n",
    "There are various frameworks such as Detectron2, mmdetection that build upon PyTorch to make DL processs more easier. We will see these frameworks later on.\n",
    "\n",
    "## 2. PyTorch Tensor\n",
    "\n",
    "Tensor is basic unit for handling numerical data for DL processing. By applying arithmetic operations, especially dot product, DL can update weights and bias of the neural network to train the model. We will see specific steps on building neural network, predicting result, computing loss function, and updating weights and bias. But in this note, I will only focus on how to use tensor through PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Import PyTorch and Check Version\n",
    "\n",
    "Let's Start with importing PyTorch and checking PyTorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.1+cu111'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scalar\n",
    "\n",
    "A Scalar is a single number like 0, 1, 2 ... However, it is in tensor form with a sero dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar:  tensor(1)\n",
      "Scalar Dimension:  0\n",
      "Scalar item:  1\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(1)\n",
    "print(\"Scalar: \", scalar)\n",
    "print(\"Scalar Dimension: \", scalar.ndim)\n",
    "print(\"Scalar item: \", scalar.item()) #Retrieving the number from the tensor. Only works for tensor with one element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vector\n",
    "\n",
    "From high school, you should rememeber what is a vector. A vector is a single dimension tensor but contains several numbers. If you are familar with programming, it is more of a like list, but in tensor form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector:  tensor([7, 7])\n",
      "Vector Dimension:  1\n",
      "Vector Shape:  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "print(\"Vector: \", vector)\n",
    "print(\"Vector Dimension: \", vector.ndim)\n",
    "print(\"Vector Shape: \", vector.shape) \n",
    "#shape returns number of element in 1 dimension tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matrix\n",
    "\n",
    "Let's move further down to matrix. You can think of matrix as concanation of multiple list in column-wise or stacking multiple lists on top of each other. Matrix is two dimension tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix: \n",
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "Matrix Dimension:  2\n",
      "Matrix Shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[7,8, 9],\n",
    "                      [10,11,12]])\n",
    "print(\"Matrix: \")\n",
    "print(matrix)\n",
    "print(\"Matrix Dimension: \", matrix.ndim)\n",
    "print(\"Matrix Shape: \", matrix.shape) #First item represent number of rows, second item represent number of columns of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tensor\n",
    "\n",
    "Now, some of you might never heard about tensor. In my case, I never heard about tensor including my high school and college, even though I am CS major :(\n",
    "\n",
    "Easy way to think of tensor is stacking the multiple matrix like a book. You can think of each page is a maxtrix with numbers. Then your are stacking matrix on top of each other which makes a book! Then, we can call book itself is a tensor. Tensor is three dimension tensor \"<b>tensor</b>\" :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]]])\n",
      "Tensor Dimension:  3\n",
      "Tensor Shape:  torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1, 2, 3],  #First page of the book\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]],\n",
    "                       [[10,11,12], #Second page of the book\n",
    "                        [13,14,15],\n",
    "                        [16,17,18]]])\n",
    "print(\"Tensor:\")\n",
    "print(tensor)\n",
    "print(\"Tensor Dimension: \" ,tensor.ndim)\n",
    "print(\"Tensor Shape: \", tensor.shape)\n",
    "#Fist item is number of page, second Item is number of rows, Third item is number of column\n",
    "#Note that number of column, number of row must be same for all pages \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful PyTorch Libary\n",
    "\n",
    "<hr>\n",
    "\n",
    "PyTorch also has various useful libaries for generating random tensor, changing shape from one dimension to other dimension. These are useful when you start implementing DL for weight calcuations and predicting results :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Random Tensor\n",
    "\n",
    "Random Tensor library assigned arbitary values into the tensor size you choose. You will see these random tensor vary often when you are initializing the weights of the baisc neural network. Specific detail about weight initialization will be discussed on in basic neural network part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vector (+ Scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random1: \n",
      "tensor([0.0696, 0.7740, 0.1112])\n",
      "Random1 Dimension:  1\n",
      "Random1 Shape:  torch.Size([3])\n",
      "Random1 data type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "random1 = torch.rand(3) \n",
    "#Generating 3 column \"Vector\" tensor\n",
    "#When you put size \"1\" it generate size 1 \"Vector\" tensor. However, it can be treated as scalar.\n",
    "print(\"Random1: \")\n",
    "print(random1)\n",
    "print(\"Random1 Dimension: \", random1.ndim)\n",
    "print(\"Random1 Shape: \", random1.shape)\n",
    "print(\"Random1 data type: \", random1.dtype)\n",
    "#Basic dtype of rand library is Float32. There are various dtype you can find in PyTorch website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random2: \n",
      "tensor([[0.7072, 0.1874],\n",
      "        [0.4934, 0.3700],\n",
      "        [0.8373, 0.3203]])\n",
      "Random2 Dimension:  2\n",
      "Random2 Shape:  torch.Size([3, 2])\n",
      "Random2 data type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "random2 = torch.rand(size=(3,2)) \n",
    "#generating 3 rows, 2 column \"Matrix\" tensor\n",
    "print(\"Random2: \")\n",
    "print(random2)\n",
    "print(\"Random2 Dimension: \", random2.ndim)\n",
    "print(\"Random2 Shape: \", random2.shape)\n",
    "print(\"Random2 data type: \", random2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random3: \n",
      "tensor([[[0.9024, 0.1928],\n",
      "         [0.8302, 0.5785],\n",
      "         [0.2093, 0.3398]],\n",
      "\n",
      "        [[0.7614, 0.3758],\n",
      "         [0.0158, 0.9138],\n",
      "         [0.8219, 0.1703]]])\n",
      "Random3 Dimension:  3\n",
      "Random3 Shape:  torch.Size([2, 3, 2])\n",
      "Random3 data type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "random3 = torch.rand(size=(2,3,2)) \n",
    "#Generating 2 dimension, 3 rows, 2 column \"Tensor\" tensor\n",
    "print(\"Random3: \")\n",
    "print(random3)\n",
    "print(\"Random3 Dimension: \", random3.ndim)\n",
    "print(\"Random3 Shape: \", random3.shape)\n",
    "print(\"Random3 data type: \", random3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Zeros and Ones\n",
    "\n",
    "Sometimes when are \"masking\" weight (which means manipulating weight for special purpose), we need zero or one values of tensor. This work exactly the same way as random tensor library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vector (+ Scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros1: \n",
      "tensor([0., 0., 0.])\n",
      "Zeros1 Dimension:  1\n",
      "Zeros1 Shape:  torch.Size([3])\n",
      "Zeros1 data type:  torch.float32\n",
      "----------------------------------\n",
      "Ones1: \n",
      "tensor([1., 1., 1.])\n",
      "Ones1 Dimension:  1\n",
      "Ones1 Shape:  torch.Size([3])\n",
      "Ones1 data type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "zeros1 = torch.zeros(3)\n",
    "print(\"Zeros1: \")\n",
    "print(zeros1)\n",
    "print(\"Zeros1 Dimension: \", zeros1.ndim)\n",
    "print(\"Zeros1 Shape: \", zeros1.shape)\n",
    "print(\"Zeros1 data type: \", zeros1.dtype)\n",
    "print(\"----------------------------------\")\n",
    "ones1 = torch.ones(3) \n",
    "print(\"Ones1: \")\n",
    "print(ones1)\n",
    "print(\"Ones1 Dimension: \", ones1.ndim)\n",
    "print(\"Ones1 Shape: \", ones1.shape)\n",
    "print(\"Ones1 data type: \", ones1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros2: \n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Zeros2 Dimension:  2\n",
      "Zeros2 Shape:  torch.Size([3, 2])\n",
      "Zeros2 data type:  torch.float32\n",
      "----------------------------------\n",
      "Ones2: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "Ones2 Dimension:  2\n",
      "Ones2 Shape:  torch.Size([3, 2])\n",
      "Ones2 data type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "zeros2 = torch.zeros(3,2)\n",
    "print(\"Zeros2: \")\n",
    "print(zeros2)\n",
    "print(\"Zeros2 Dimension: \", zeros2.ndim)\n",
    "print(\"Zeros2 Shape: \", zeros2.shape)\n",
    "print(\"Zeros2 data type: \", zeros2.dtype)\n",
    "print(\"----------------------------------\")\n",
    "ones2 = torch.ones(3,2)\n",
    "print(\"Ones2: \")\n",
    "print(ones2)\n",
    "print(\"Ones2 Dimension: \", ones2.ndim)\n",
    "print(\"Ones2 Shape: \", ones2.shape)\n",
    "print(\"Ones2 data type: \", ones2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros3: \n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "Zeros3 Dimension:  3\n",
      "Zeros3 Shape:  torch.Size([2, 3, 2])\n",
      "Zeros3 data type:  torch.float32\n",
      "----------------------------------\n",
      "Ones3: \n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n",
      "Ones3 Dimension:  3\n",
      "Ones3 Shape:  torch.Size([2, 3, 2])\n",
      "Ones3 data type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "zeros3 = torch.zeros(2, 3,2)\n",
    "print(\"Zeros3: \")\n",
    "print(zeros3)\n",
    "print(\"Zeros3 Dimension: \", zeros3.ndim)\n",
    "print(\"Zeros3 Shape: \", zeros3.shape)\n",
    "print(\"Zeros3 data type: \", zeros3.dtype)\n",
    "print(\"----------------------------------\")\n",
    "ones3 = torch.ones(2,3,2)\n",
    "print(\"Ones3: \")\n",
    "print(ones3)\n",
    "print(\"Ones3 Dimension: \", ones3.ndim)\n",
    "print(\"Ones3 Shape: \", ones3.shape)\n",
    "print(\"Ones3 data type: \", ones3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Ranging Tensors\n",
    "\n",
    "Rangind tensor library enables user to set start and end number with specific step to generate the tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range:\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Range Dimension:  1\n",
      "Range Shape:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "range = torch.arange(start=-0, end=10, step=1)\n",
    "print(\"Range:\")\n",
    "print(range)\n",
    "print(\"Range Dimension: \", range.ndim)\n",
    "print(\"Range Shape: \", range.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Manipulating Tensor (Arithmetic Operation)\n",
    "\n",
    "In DL, changing values of weights and bias are key operation of training the neural network model. In order to change the values, performing series of arithmetic operation is required such as\n",
    "\n",
    "* Addion\n",
    "* Subtraction\n",
    "* Multiplication (Element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication or dot product\n",
    "\n",
    "If you are not sure about each of the step, I will show specific steps of each calculation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Operation: Broadcast\n",
    "\n",
    "You all know addition, subtraction, multiplication, and division from your elementry school. Performing basic arithmetic operation in tensor are exactly the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([10, 20, 30])\n",
      "\n",
      "Addition: \n",
      " tensor([20, 30, 40])\n",
      "\n",
      "Subtraction: \n",
      " tensor([ 0, 10, 20])\n",
      "\n",
      "Multiplication: \n",
      " tensor([100, 200, 300])\n",
      "\n",
      "Division: \n",
      " tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([10,20,30])\n",
    "print(\"Tensor: \\n\", tensor)\n",
    "# Addition\n",
    "addition = tensor + 10\n",
    "print(\"\\nAddition: \\n\", addition)\n",
    "\n",
    "# Subtraction\n",
    "subtraction = tensor - 10\n",
    "print(\"\\nSubtraction: \\n\", subtraction)\n",
    "\n",
    "# Multiplication\n",
    "multiplication = tensor * 10\n",
    "print(\"\\nMultiplication: \\n\", multiplication)\n",
    "\n",
    "# Division\n",
    "division = tensor / 10\n",
    "print(\"\\nDivision: \\n\", division)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Operation: Element-Wise\n",
    "\n",
    "After performing arithemetic operation by broadcasting a single value onto the vector, arithemetic operation can be performed in \"Element-Wise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Tensor2: \n",
      " tensor([[2, 3, 4],\n",
      "        [5, 6, 7]])\n",
      "\n",
      "Addition: \n",
      " tensor([[ 3,  5,  7],\n",
      "        [ 9, 11, 13]])\n",
      "\n",
      "Subtraction: \n",
      " tensor([[-1, -1, -1],\n",
      "        [-1, -1, -1]])\n",
      "\n",
      "Multiplication: \n",
      " tensor([[ 2,  6, 12],\n",
      "        [20, 30, 42]])\n",
      "\n",
      "Division: \n",
      " tensor([[0.5000, 0.6667, 0.7500],\n",
      "        [0.8000, 0.8333, 0.8571]])\n"
     ]
    }
   ],
   "source": [
    "#Tensors\n",
    "tensor = torch.tensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "\n",
    "tensor2 = torch.tensor([[2,3,4],\n",
    "                        [5,6,7]])\n",
    "print(\"Tensor: \\n\", tensor)\n",
    "print(\"\\nTensor2: \\n\", tensor2)\n",
    "\n",
    "# Addition\n",
    "addition = tensor + tensor2\n",
    "print(\"\\nAddition: \\n\", addition)\n",
    "\n",
    "# Subtraction\n",
    "subtraction = tensor - tensor2\n",
    "print(\"\\nSubtraction: \\n\", subtraction)\n",
    "\n",
    "# Multiplication\n",
    "multiplication = tensor * tensor2\n",
    "print(\"\\nMultiplication: \\n\", multiplication)\n",
    "\n",
    "# Division\n",
    "division = tensor / tensor2\n",
    "print(\"\\nDivision: \\n\", division)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multiplication (Dot-Product)\n",
    "\n",
    "Matrix multiplication or dot product is multiplying each row of the first matrix onto each column of the second matrix. Calculation method for vector and matrix is a bit different. \n",
    "\n",
    "Assume we have vector = [1,2,3]\n",
    "\n",
    "| Operation | Calculation | Code |\n",
    "| ----- | ----- | ----- |\n",
    "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "| **Vector multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Vector Muliplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([1,2,3])\n",
    "torch.matmul(vector, vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Matrix Muliplication\n",
    "\n",
    "1. The **inner dimensions** must match:\n",
    "  * `(3, 2) @ (3, 2)` won't work\n",
    "  * `(2, 3) @ (3, 2)` will work\n",
    "  * `(3, 2) @ (2, 3)` will work\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "matrix2 = torch.tensor([[1,4],\n",
    "                        [2,5],\n",
    "                        [3,6]])\n",
    "torch.matmul(matrix, matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Common mistak on matrix multiplication and solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes need to be in the right way  \n",
    "matrix = torch.tensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "matrix2 = torch.tensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "\n",
    "#torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix: \n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Matrix2: \n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Matrix2 Transpose: \n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "\n",
      "Matrix Multiplication: \n",
      " tensor([[14, 32],\n",
      "        [32, 77]])\n"
     ]
    }
   ],
   "source": [
    "tensor_result = torch.mm(matrix, matrix2.T)\n",
    "print(\"Matrix: \\n\", matrix)\n",
    "print(\"\\nMatrix2: \\n\", matrix2)\n",
    "print(\"\\nMatrix2 Transpose: \\n\", matrix2.T)\n",
    "print(\"\\nMatrix Multiplication: \\n\", tensor_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Tensor Analysis\n",
    "\n",
    "Like numpy and pandas, PyTorch tensor also provide useful tool for analyze numbers of the tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max, Min, Mean, Sum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([ 10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.])\n",
      "\n",
      "Max: \n",
      " torch.return_types.max(\n",
      "values=tensor(100.),\n",
      "indices=tensor(9))\n",
      "\n",
      "Min: \n",
      " torch.return_types.min(\n",
      "values=tensor(10.),\n",
      "indices=tensor(0))\n",
      "\n",
      "Mean: \n",
      " tensor(55.)\n",
      "\n",
      "Sum: \n",
      " tensor(550.)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10.0,110.0,10.0)\n",
    "print(\"Tensor: \\n\", tensor)\n",
    "print(\"\\nMax: \\n\", torch.max(tensor, 0))\n",
    "print(\"\\nMin: \\n\", torch.min(tensor, 0))\n",
    "print(\"\\nMean: \\n\", tensor.mean())\n",
    "print(\"\\nSum: \\n\", tensor.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([[0.4391, 0.1579],\n",
      "        [0.2629, 0.1590],\n",
      "        [0.8009, 0.8872]])\n",
      "\n",
      "Axis 0 Max: \n",
      " torch.return_types.max(\n",
      "values=tensor([0.8009, 0.8872]),\n",
      "indices=tensor([2, 2]))\n",
      "\n",
      "Axis 1 Max: \n",
      " torch.return_types.max(\n",
      "values=tensor([0.4391, 0.2629, 0.8872]),\n",
      "indices=tensor([0, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,2)\n",
    "print(\"Tensor: \\n\", tensor)\n",
    "print(\"\\nAxis 0 Max: \\n\", torch.max(tensor, 0))\n",
    "print(\"\\nAxis 1 Max: \\n\", torch.max(tensor, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([[[0.1691, 0.0228],\n",
      "         [0.1954, 0.2037],\n",
      "         [0.2305, 0.8955]],\n",
      "\n",
      "        [[0.3570, 0.3020],\n",
      "         [0.0480, 0.4371],\n",
      "         [0.7935, 0.0069]]])\n",
      "\n",
      "Axis 0 Max: \n",
      " torch.return_types.max(\n",
      "values=tensor([[0.3570, 0.3020],\n",
      "        [0.1954, 0.4371],\n",
      "        [0.7935, 0.8955]]),\n",
      "indices=tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]]))\n",
      "\n",
      "Axis 1 Max: \n",
      " torch.return_types.max(\n",
      "values=tensor([[0.2305, 0.8955],\n",
      "        [0.7935, 0.4371]]),\n",
      "indices=tensor([[2, 2],\n",
      "        [2, 1]]))\n",
      "\n",
      "Axis 2 Max: \n",
      " torch.return_types.max(\n",
      "values=tensor([[0.1691, 0.2037, 0.8955],\n",
      "        [0.3570, 0.4371, 0.7935]]),\n",
      "indices=tensor([[0, 1, 1],\n",
      "        [0, 1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(2, 3,2)\n",
    "print(\"Tensor: \\n\", tensor)\n",
    "print(\"\\nAxis 0 Max: \\n\", torch.max(tensor, 0))\n",
    "print(\"\\nAxis 1 Max: \\n\", torch.max(tensor, 1))\n",
    "print(\"\\nAxis 2 Max: \\n\", torch.max(tensor, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Change Data Type\n",
    "\n",
    "When operating arithematic computation between or among different tensors, not only matching the inner size of the tensors is important but also matching the type of the tensor is essential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([0.0864, 0.0423, 0.8625, 0.2813, 0.9311, 0.5569, 0.9499, 0.4768, 0.3788,\n",
      "        0.7359])\n",
      "\n",
      "Tensor data type: \n",
      " torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(10)\n",
    "print(\"Tensor: \\n\", tensor)\n",
    "print(\"\\nTensor data type: \\n\", tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([0.0864, 0.0423, 0.8623, 0.2812, 0.9312, 0.5571, 0.9497, 0.4768, 0.3789,\n",
      "        0.7358], dtype=torch.float16)\n",
      "\n",
      "Tensor data type: \n",
      " torch.float16\n"
     ]
    }
   ],
   "source": [
    "tensor_to_float16 = tensor.type(torch.float16)\n",
    "print(\"Tensor: \\n\", tensor_to_float16)\n",
    "print(\"\\nTensor data type: \\n\", tensor_to_float16.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int8)\n",
      "\n",
      "Tensor data type: \n",
      " torch.int8\n"
     ]
    }
   ],
   "source": [
    "tensor_to_int8 = tensor.type(torch.int8)\n",
    "print(\"Tensor: \\n\", tensor_to_int8)\n",
    "print(\"\\nTensor data type: \\n\", tensor_to_int8.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maptr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
